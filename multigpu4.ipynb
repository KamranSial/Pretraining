{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import vgg16_trainable as vgg16\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "PRETRAINED_MODEL_PATH= None #\"/home/sik4hi/ckpt_dir\"\n",
    "N_EPOCHS = 300\n",
    "INIT_LEARNING_RATE = 0.01\n",
    "WEIGHT_DECAY_RATE = 0.0005\n",
    "MOMENTUM = 0.9\n",
    "IMAGE_HEIGHT  = 224    #960\n",
    "IMAGE_WIDTH   = 224    #720\n",
    "NUM_CHANNELS  = 3\n",
    "BATCH_SIZE = 90\n",
    "N_CLASSES = 1000\n",
    "DROPOUT = 0.50\n",
    "ckpt_dir = \"/home/sik4hi/ckpt_dir\"\n",
    "LOGS_PATH = '/home/sik4hi/tensorflow_logs'\n",
    "WEIGHT_PATH = '.npy'\n",
    "TRAINSET_PATH0 = '/mnt/data1/imagenet-data/csv-files/train/imagenetdata0.csv'\n",
    "TRAINSET_PATH1 = '/mnt/data1/imagenet-data/csv-files/train/imagenetdata1.csv'\n",
    "TRAINSET_PATH2 = '/mnt/data1/imagenet-data/csv-files/train/imagenetdata2.csv'\n",
    "TRAINSET_PATH3 = '/mnt/data1/imagenet-data/csv-files/train/imagenetdata3.csv'\n",
    "TRAINSET_PATH4 = '/mnt/data1/imagenet-data/csv-files/train/imagenetdata4.csv'\n",
    "TRAINSET_PATH5 = '/mnt/data1/imagenet-data/csv-files/train/imagenetdata5.csv'\n",
    "TRAINSET_PATH6 = '/mnt/data1/imagenet-data/csv-files/train/imagenetdata6.csv'\n",
    "TRAINSET_PATH7 = '/mnt/data1/imagenet-data/csv-files/train/imagenetdata7.csv'\n",
    "TRAINSET_PATH8 = '/mnt/data1/imagenet-data/csv-files/train/imagenetdata8.csv'\n",
    "TRAINSET_PATH9 = '/mnt/data1/imagenet-data/csv-files/train/imagenetdata9.csv'\n",
    "\n",
    "VALSET_PATH0 ='/mnt/data1/imagenet-data/csv-files/val/imagenetdata0.csv'\n",
    "VALSET_PATH1 ='/mnt/data1/imagenet-data/csv-files/val/imagenetdata1.csv'\n",
    "VALSET_PATH2 ='/mnt/data1/imagenet-data/csv-files/val/imagenetdata2.csv'\n",
    "VALSET_PATH3 ='/mnt/data1/imagenet-data/csv-files/val/imagenetdata3.csv'\n",
    "VALSET_PATH4 ='/mnt/data1/imagenet-data/csv-files/val/imagenetdata4.csv'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    def _compute_longer_edge(height, width, new_shorter_edge):\n",
    "        return tf.cast(width*new_shorter_edge/height, tf.int32)\n",
    "    \n",
    "    csv_path = tf.train.string_input_producer([TRAINSET_PATH0, TRAINSET_PATH1\n",
    "                                              , TRAINSET_PATH2, TRAINSET_PATH3,\n",
    "                                               TRAINSET_PATH4, TRAINSET_PATH5\n",
    "                                              , TRAINSET_PATH6, TRAINSET_PATH7, \n",
    "                                               TRAINSET_PATH8, TRAINSET_PATH9\n",
    "                                              ], shuffle=True)\n",
    "    textReader = tf.TextLineReader()\n",
    "    _, csv_content = textReader.read(csv_path)\n",
    "    im_name, im_label = tf.decode_csv(csv_content, record_defaults=[[\"\"], [1]])\n",
    "\n",
    "    im_content = tf.read_file(im_name)\n",
    "    train_image = tf.image.decode_jpeg(im_content, channels=3)\n",
    "    \n",
    "    # train_image = augment(train_image)\n",
    "    #size = tf.cast([IMAGE_HEIGHT, IMAGE_WIDTH], tf.int32)\n",
    "    #train_image = tf.image.resize_images(train_image, size)\n",
    "    train_label = tf.cast(im_label, tf.int64) # unnecessary\n",
    "    \n",
    "    shape = tf.shape(train_image)\n",
    "    height = shape[0]\n",
    "    width = shape[1]\n",
    "    new_shorter_edge = tf.constant(256, dtype=tf.int32)\n",
    "\n",
    "    height_smaller_than_width = tf.less_equal(height, width)\n",
    "    new_height_and_width = tf.cond(\n",
    "        height_smaller_than_width,\n",
    "        lambda: (new_shorter_edge, _compute_longer_edge(height, width, new_shorter_edge)),\n",
    "        lambda: (_compute_longer_edge(width, height, new_shorter_edge), new_shorter_edge)\n",
    "    )\n",
    "    size = tf.cast([new_height_and_width[0], new_height_and_width[1]], tf.int32)\n",
    "    train_image = tf.image.resize_images(train_image, size)\n",
    "    size = tf.cast([IMAGE_HEIGHT, IMAGE_WIDTH, 3], tf.int32)\n",
    "    train_image = tf.random_crop(train_image, size)\n",
    "    train_image = tf.image.random_flip_left_right(train_image)\n",
    "    train_image = tf.cast(train_image, tf.float32)/255. # necessary for mapping rgb channels from 0-255 to 0-1 float.\n",
    "    #train_label_batch = tf.one_hot(train_label_batch, 1000)\n",
    "    train_image_batch, train_label_batch = tf.train.shuffle_batch([train_image, train_label], batch_size=BATCH_SIZE,\n",
    "                                                                  capacity = 1000 + 3*BATCH_SIZE, min_after_dequeue = 1000)\n",
    "\n",
    "    val_csv_path = tf.train.string_input_producer([VALSET_PATH0\n",
    "                                                   , VALSET_PATH1,\n",
    "                                                   VALSET_PATH2, VALSET_PATH3, \n",
    "                                                   VALSET_PATH4\n",
    "                                                  ], shuffle=True)\n",
    "    val_textReader = tf.TextLineReader()\n",
    "    _, val_content = val_textReader.read(val_csv_path)\n",
    "    val_image, val_label = tf.decode_csv(val_content, record_defaults=[[\"\"], [1]])\n",
    "\n",
    "    val_image_content = tf.read_file(val_image)\n",
    "    val_image = tf.image.decode_jpeg(val_image_content, channels=3)\n",
    "    \n",
    "\n",
    "    shape = tf.shape(val_image)\n",
    "    height = shape[0]\n",
    "    width = shape[1]\n",
    "    new_shorter_edge = tf.constant(256, dtype=tf.int32)\n",
    "    height_smaller_than_width = tf.less_equal(height, width)\n",
    "    new_height_and_width = tf.cond(\n",
    "        height_smaller_than_width,\n",
    "        lambda: (new_shorter_edge, _compute_longer_edge(height, width, new_shorter_edge)),\n",
    "        lambda: (_compute_longer_edge(width, height, new_shorter_edge), new_shorter_edge)\n",
    "    )\n",
    "    size = tf.cast([new_height_and_width[0], new_height_and_width[1]], tf.int32)\n",
    "    val_image = tf.image.resize_images(val_image, size)\n",
    "    size = tf.cast([IMAGE_HEIGHT, IMAGE_WIDTH, 3], tf.int32)\n",
    "    val_image = tf.random_crop(val_image, size)\n",
    "    #val_image = tf.image.random_flip_left_right(val_image)\n",
    "    val_image = tf.cast(val_image, tf.float32) / 255. # necessary\n",
    "\n",
    "\n",
    "    val_label = tf.cast(val_label, tf.int64) # unnecessary\n",
    "    val_image_batch, val_label_batch = tf.train.shuffle_batch([val_image, val_label], batch_size=BATCH_SIZE,\n",
    "                                                              allow_smaller_final_batch=True,\n",
    "                                                              capacity = 1000 + 3*BATCH_SIZE, min_after_dequeue = 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = tf.placeholder(tf.float32, [])\n",
    "images_tf = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "labels_tf = tf.placeholder(tf.int64)\n",
    "train_mode = tf.placeholder(tf.bool)\n",
    "\n",
    "vgg = vgg16.Vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _tower_loss(images, labels,train_mode, scope):\n",
    "    \n",
    "    vgg.build(images, train_mode)\n",
    "    weights_only = filter(lambda x: x.name.endswith('W:0'), tf.trainable_variables())\n",
    "    for x in xrange(len(weights_only)):\n",
    "        print (weights_only[x].name)\n",
    "    # print number of variables used: 143667240 variables, i.e. ideal size = 548MB\n",
    "    print vgg.get_var_count()\n",
    "    \n",
    "    # Build the portion of the Graph calculating the losses. Note that we will\n",
    "    # assemble the total_loss using a custom function below.\n",
    "    loss_tf = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(vgg.prob, labels), name='loss_tf')\n",
    "    #loss_summary = tf.summary.scalar(\"loss\", loss_tf)\n",
    "    weights_only = filter( lambda x: x.name.endswith('W:0'), tf.trainable_variables())\n",
    "    weight_decay = tf.reduce_mean(tf.add_n([tf.nn.l2_loss(x) for x in weights_only])) * WEIGHT_DECAY_RATE\n",
    "    total_loss = loss_tf + weight_decay\n",
    "    \n",
    "    correct_pred = tf.equal(tf.argmax(vgg.prob, 1), labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    \n",
    "    return total_loss,loss_tf, accuracy\n",
    "\n",
    "\n",
    "def _average_gradients(tower_grads):\n",
    "\n",
    "    average_grads = []\n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "        # Note that each grad_and_vars looks like the following:\n",
    "        #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n",
    "        grads = []\n",
    "        for g, _ in grad_and_vars:\n",
    "            # Add 0 dimension to the gradients to represent the tower.\n",
    "            expanded_g = tf.expand_dims(g, 0)\n",
    "\n",
    "            # Append on a 'tower' dimension which we will average over below.\n",
    "            grads.append(expanded_g)\n",
    "\n",
    "        # Average over the 'tower' dimension.\n",
    "        grad = tf.concat(0, grads)\n",
    "        grad = tf.reduce_mean(grad, 0)\n",
    "\n",
    "        # Keep in mind that the Variables are redundant because they are shared\n",
    "        # across towers. So .. we will just return the first tower's pointer to\n",
    "        # the Variable.\n",
    "        v = grad_and_vars[0][1]\n",
    "        grad_and_var = (grad, v)\n",
    "        average_grads.append(grad_and_var)\n",
    "    return average_grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_step = tf.get_variable('global_step', [], initializer=tf.constant_initializer(0), trainable=False)\n",
    "\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "saver = tf.train.Saver(max_to_keep=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = tf.train.AdamOptimizer(learning_rate=0.01,epsilon=0.1)\n",
    "# Get images and labels for ImageNet and split the batch across GPUs.\n",
    "assert BATCH_SIZE % NUM_GPUS == 0, ('Batch size must be divisible by number of GPUs')\n",
    "split_batch_size = int(BATCH_SIZE / NUM_GPUS) # print this in sess out\n",
    "\n",
    "# Override the number of preprocessing threads to account for the increased\n",
    "# number of GPU towers.\n",
    "        \n",
    "##num_preprocess_threads = FLAGS.num_preprocess_threads * FLAGS.num_gpus\n",
    "       \n",
    "#images, labels = image_processing.distorted_inputs(dataset,\n",
    "#    num_preprocess_threads=num_preprocess_threads)\n",
    "\n",
    "#input_summaries = copy.copy(tf.get_collection(tf.GraphKeys.SUMMARIES))\n",
    "\n",
    "# Number of classes in the Dataset label set plus 1.\n",
    "# Label 0 is reserved for an (unused) background class.\n",
    "        \n",
    "##num_classes = dataset.num_classes() + 1\n",
    "    \n",
    "# Split the batch of images and labels for towers.\n",
    "images_splits = tf.split(0, NUM_GPUS, images_tf)\n",
    "labels_splits = tf.split(0, NUM_GPUS, labels_tf)\n",
    "\n",
    "\n",
    "print 'im_split', np.shape(images_splits)\n",
    "print 'la_split', np.shape(labels_splits)\n",
    "\n",
    "# Calculate the gradients for each model tower.\n",
    "tower_grads = []\n",
    "acc_array=[]\n",
    "for i in xrange(NUM_GPUS):\n",
    "    with tf.device('/gpu:%d' % i):\n",
    "        with tf.name_scope('%s_%d' % ('tower', i)) as scope:\n",
    "            # Force all Variables to reside on the CPU.\n",
    "            #with slim.arg_scope([slim.variables.variable], device='/cpu:0'):\n",
    "                # Calculate the loss for one tower of the ImageNet model. This\n",
    "                # function constructs the entire ImageNet model but shares the\n",
    "                # variables across all towers.\n",
    "            #loss, acc, output = _tower_loss(images_splits[i], labels_splits[i], scope)\n",
    "            total_loss, loss, acc = _tower_loss(images_tf, labels_tf, scope)\n",
    "            acc_array.append(acc)\n",
    "            # Reuse variables for the next tower.\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "                # Retain the summaries from the final tower.\n",
    "                #summaries = tf.get_collection(tf.GraphKeys.SUMMARIES, scope)\n",
    "\n",
    "                # Retain the Batch Normalization updates operations only from the\n",
    "                # final tower. Ideally, we should grab the updates from all towers\n",
    "                # but these stats accumulate extremely fast so we can ignore the\n",
    "                # other stats from the other towers without significant detriment.\n",
    "                #batchnorm_updates = tf.get_collection(slim.ops.UPDATE_OPS_COLLECTION, scope)\n",
    "\n",
    "                # Calculate the gradients for the batch of data on this ImageNet\n",
    "                # tower.\n",
    "            grads = opt.compute_gradients(total_loss)\n",
    "\n",
    "                # Keep track of the gradients across all towers.\n",
    "            tower_grads.append(grads)\n",
    "\n",
    "accuracy = (sum(acc_array))/2.\n",
    "acc_array=[]\n",
    "    # We must calculate the mean of each gradient. Note that this is the\n",
    "    # synchronization point across all towers.\n",
    "grads = _average_gradients(tower_grads)\n",
    "\n",
    "    # Add a summaries for the input processing and global_step.\n",
    "    #summaries.extend(input_summaries)\n",
    "\n",
    "    # Add a summary to track the learning rate.\n",
    "    #summaries.append(tf.scalar_summary('learning_rate', lr))\n",
    "\n",
    "    # Add histograms for gradients.\n",
    "    #for grad, var in grads:\n",
    "    #    if grad is not None:\n",
    "    #        summaries.append(tf.histogram_summary(var.op.name + '/gradients', grad))\n",
    "\n",
    "    # Apply the gradients to adjust the shared variables.\n",
    "train_op= opt.apply_gradients(grads, global_step=global_step)\n",
    "##apply_gradient_op= opt.apply_gradients(grads, global_step=global_step)\n",
    "    # Add histograms for trainable variables.\n",
    "    #for var in tf.trainable_variables():\n",
    "    #    summaries.append(tf.histogram_summary(var.op.name, var))\n",
    "\n",
    "    # Track the moving averages of all trainable variables.\n",
    "    # Note that we maintain a \"double-average\" of the BatchNormalization\n",
    "    # global statistics. This is more complicated then need be but we employ\n",
    "    # this for backward-compatibility with our previous models.\n",
    "            \n",
    "##variable_averages = tf.train.ExponentialMovingAverage(0.9999, global_step)  # Moving Average Decay\n",
    "\n",
    "    # Another possiblility is to use tf.slim.get_variables().\n",
    "    ##variables_to_average = (tf.trainable_variables() +\n",
    "    #                        tf.moving_average_variables())\n",
    "##variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "    # Group all updates to into a single train op.\n",
    "    #batchnorm_updates_op = tf.group(*batchnorm_updates)\n",
    "##train_op = tf.group(apply_gradient_op, variables_averages_op)\n",
    "\n",
    "    # Create a saver.\n",
    "saver = tf.train.Saver(tf.all_variables())\n",
    "\n",
    "    # Build the summary operation from the last tower summaries.\n",
    "    #summary_op = tf.merge_summary(summaries)\n",
    "    \n",
    "    # Build an initialization operation to run below.\n",
    "    #init = tf.initialize_all_variables()\n",
    "\n",
    "    # Start running operations on the Graph. allow_soft_placement must be set to\n",
    "    # True to build towers on GPU, as some of the ops do not have GPU\n",
    "    # implementations.\n",
    "with tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True)) as sess:\n",
    "    \n",
    "    if PRETRAINED_MODEL_PATH:\n",
    "        print \"Using Pretrained model\"\n",
    "        saver.restore(sess, PRETRAINED_MODEL_PATH)\n",
    "    else:    \n",
    "        sess.run(tf.initialize_all_variables())    \n",
    "        #sess.run(tf.initialize_local_variables())\n",
    "    #coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess)\n",
    "    loss_list, train_list, plot_loss, plot_acc , loss_list2 , val_list ,plot_loss2, plot_acc2, total_loss_list1, total_loss_list2, plot_ttloss, plot_tvloss  = [], [], [], [], [], [], [], [], [], [], [], []\n",
    "    time_per_epoch=[]\n",
    "    \n",
    "    for epoch in xrange(N_EPOCHS):\n",
    "\n",
    "        train_correct = 0\n",
    "        train_data = 0\n",
    "        epoch_start_time = time.time()\n",
    "        iteration_start_time = time.time()\n",
    "        print((1281144 / BATCH_SIZE))\n",
    "        #print((2600 / BATCH_SIZE) + 1)\n",
    "        for i in xrange((1281144/ BATCH_SIZE)):\n",
    "            train_imbatch, train_labatch = sess.run([train_image_batch, train_label_batch])\n",
    "            _, train_loss,total_loss, train_accuracy = sess.run(\n",
    "               [train_op, loss_tf, loss_tf2, accuracy],\n",
    "               feed_dict={learning_rate: INIT_LEARNING_RATE, images_tf: train_imbatch, labels_tf:\n",
    "               train_labatch, train_mode: True})\n",
    "\n",
    "            loss_list.append(train_loss)\n",
    "            train_list.append(train_accuracy)\n",
    "            total_loss_list1.append(total_loss)\n",
    "            sys.stdout.write('\\r' + 'iteration:' + str(i))\n",
    "            sys.stdout.flush()\n",
    "            if (i) % 10 == 0:\n",
    "                print ' Time Elapsed for 10 Iterations:' + str(i) + ' is ' + str(\n",
    "                   (time.time() - iteration_start_time)) + ' Seconds' \n",
    "                iteration_start_time = time.time()\n",
    "        \n",
    "        \n",
    "        tt = np.mean(train_list)\n",
    "        tl = np.mean(loss_list)\n",
    "        ttl = np.mean(total_loss_list1)\n",
    "        \n",
    "        \n",
    "        plot_loss.append(tl)\n",
    "        plot_acc.append(tt)\n",
    "        plot_ttloss.append(ttl)\n",
    "      \n",
    "      \n",
    "                #summary_writer.add_summary(summary_str, steps)\n",
    "        loss_list = []\n",
    "        train_list = []\n",
    "        total_loss_list1=[]\n",
    "                \n",
    "            \n",
    "        #INIT_LEARNING_RATE *= 0.99\n",
    "\n",
    "        for i in xrange((50000 / BATCH_SIZE) ):\n",
    "            val_imbatch, val_labatch = sess.run([val_image_batch, val_label_batch])\n",
    "            val_accuracy, val_loss, val_tloss = sess.run([accuracy, loss_tf, loss_tf2], feed_dict={images_tf: val_imbatch, labels_tf: val_labatch, train_mode: False})\n",
    "            loss_list2.append(val_loss)\n",
    "            val_list.append(val_accuracy)\n",
    "            total_loss_list2.append(val_tloss)\n",
    "            sys.stdout.write('\\r' + 'iteration:' + str(i))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "        vt = np.mean(val_list)\n",
    "        vl = np.mean(loss_list2)\n",
    "        tvl = np.mean(total_loss_list2)\n",
    "        # #f_log.write('epoch:' + str(epoch + 1) + '\\tacc:' + str(val_accuracy) + '\\n')\n",
    "        clear_output()\n",
    "        print \"===========**Training ACCURACY**================\"\n",
    "        print \"Epoch\", epoch + 1#, \"Iteration\", steps\n",
    "        #print \"Processed\", train_data, '/', 7800  # (count*BATCH_SIZE)\n",
    "        print 'Training Accuracy: ', tt\n",
    "        #print 'labels: ', train_labatch\n",
    "        \n",
    "        print \"Training Loss:\", tl \n",
    "        print \"Total Training Loss:\", ttl\n",
    "        \n",
    "        print \"===========**VALIDATION ACCURACY**================\"\n",
    "        print 'Epoch:' + str(epoch + 1)# + '\\tacc:' + str(val_accuracy) + '\\n'\n",
    "        print 'Validation Accuracy: ', vt\n",
    "        #print 'labels: ', train_labatch\n",
    "        print \"Validation Loss:\", vl \n",
    "        print \"Total Validation Loss:\", tvl\n",
    "        print 'Time Elapsed for Epoch:' + str(epoch + 1) + ' is ' + str(\n",
    "            (time.time() - epoch_start_time) / 60.) + ' minutes'\n",
    "        plot_loss2.append(vl)\n",
    "        plot_acc2.append(vt)\n",
    "        plot_tvloss.append(tvl)\n",
    "        \n",
    "        plt.figure(1) \n",
    "        aa = plt.plot(plot_ttloss,'r',label=\"Training\")\n",
    "        bb = plt.plot(plot_tvloss,'g',label=\"Validation\")\n",
    "        plt.title(\"TOTAL LOSS\")\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        plt.figure(2) \n",
    "        aa = plt.plot(plot_loss,'r',label=\"Training\")\n",
    "        bb = plt.plot(plot_loss2,'g',label=\"Validation\")\n",
    "        plt.title(\"LOSS\")\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        plt.figure(3)\n",
    "        cc = plt.plot(plot_acc,'r',label=\"Training\")\n",
    "        dd = plt.plot(plot_acc2,'g',label=\"Validation\")\n",
    "        plt.title(\"Accuracy\")\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        plt.show()\n",
    "        loss_list2 = []\n",
    "        val_list = []\n",
    "        toltal_loss_list2=[]\n",
    "        if (epoch % 1 == 0):            \n",
    "            saver.save(sess, ckpt_dir + \"/model.ckpt\", global_step=epoch)\n",
    "    # test savel\n",
    "        vgg.save_npy(sess, '/mnt/data1/imagenet-data/weights/vgg-epoch-' + str(epoch) + '.npy')\n",
    "        ofile  = open('data.csv', \"a\")\n",
    "        writer = csv.writer(ofile)\n",
    "        writer.writerow([tl,ttl,tt,vl,tvl,vt])\n",
    "        ofile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
