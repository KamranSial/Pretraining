{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded\n",
      "('conv1_1', 'Value Loaded')\n",
      "conv1_1_filters_W [3, 3, 3, 64]\n",
      "('conv1_1', 'L2 Loss Added')\n",
      "('conv1_1', 'Value Loaded')\n",
      "conv1_1_biases [64]\n",
      "('conv1_2', 'Value Loaded')\n",
      "conv1_2_filters_W [3, 3, 64, 64]\n",
      "('conv1_2', 'L2 Loss Added')\n",
      "('conv1_2', 'Value Loaded')\n",
      "conv1_2_biases [64]\n",
      "('conv2_1', 'Value Loaded')\n",
      "conv2_1_filters_W [3, 3, 64, 128]\n",
      "('conv2_1', 'L2 Loss Added')\n",
      "('conv2_1', 'Value Loaded')\n",
      "conv2_1_biases [128]\n",
      "('conv2_2', 'Value Loaded')\n",
      "conv2_2_filters_W [3, 3, 128, 128]\n",
      "('conv2_2', 'L2 Loss Added')\n",
      "('conv2_2', 'Value Loaded')\n",
      "conv2_2_biases [128]\n",
      "('conv3_1', 'Value Loaded')\n",
      "conv3_1_filters_W [3, 3, 128, 256]\n",
      "('conv3_1', 'L2 Loss Added')\n",
      "('conv3_1', 'Value Loaded')\n",
      "conv3_1_biases [256]\n",
      "('conv3_2', 'Value Loaded')\n",
      "conv3_2_filters_W [3, 3, 256, 256]\n",
      "('conv3_2', 'L2 Loss Added')\n",
      "('conv3_2', 'Value Loaded')\n",
      "conv3_2_biases [256]\n",
      "('conv3_3', 'Value Loaded')\n",
      "conv3_3_filters_W [3, 3, 256, 256]\n",
      "('conv3_3', 'L2 Loss Added')\n",
      "('conv3_3', 'Value Loaded')\n",
      "conv3_3_biases [256]\n",
      "('conv4_1', 'Value Loaded')\n",
      "conv4_1_filters_W [3, 3, 256, 512]\n",
      "('conv4_1', 'L2 Loss Added')\n",
      "('conv4_1', 'Value Loaded')\n",
      "conv4_1_biases [512]\n",
      "('conv4_2', 'Value Loaded')\n",
      "conv4_2_filters_W [3, 3, 512, 512]\n",
      "('conv4_2', 'L2 Loss Added')\n",
      "('conv4_2', 'Value Loaded')\n",
      "conv4_2_biases [512]\n",
      "('conv4_3', 'Value Loaded')\n",
      "conv4_3_filters_W [3, 3, 512, 512]\n",
      "('conv4_3', 'L2 Loss Added')\n",
      "('conv4_3', 'Value Loaded')\n",
      "conv4_3_biases [512]\n",
      "('conv5_1', 'Value Loaded')\n",
      "conv5_1_filters_W [3, 3, 512, 512]\n",
      "('conv5_1', 'L2 Loss Added')\n",
      "('conv5_1', 'Value Loaded')\n",
      "conv5_1_biases [512]\n",
      "('conv5_2', 'Value Loaded')\n",
      "conv5_2_filters_W [3, 3, 512, 512]\n",
      "('conv5_2', 'L2 Loss Added')\n",
      "('conv5_2', 'Value Loaded')\n",
      "conv5_2_biases [512]\n",
      "('conv5_3', 'Value Loaded')\n",
      "conv5_3_filters_W [3, 3, 512, 512]\n",
      "('conv5_3', 'L2 Loss Added')\n",
      "('conv5_3', 'Value Loaded')\n",
      "conv5_3_biases [512]\n",
      "('fc6', 'Value Loaded')\n",
      "fc6_weights_W [25088, 4096]\n",
      "('fc6', 'L2 Loss Added')\n",
      "('fc6', 'Value Loaded')\n",
      "fc6_biases [4096]\n",
      "('fc7', 'Value Loaded')\n",
      "fc7_weights_W [4096, 4096]\n",
      "('fc7', 'L2 Loss Added')\n",
      "('fc7', 'Value Loaded')\n",
      "fc7_biases [4096]\n",
      "('fc8', 'Value Loaded')\n",
      "fc8_weights_W [4096, 1000]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-fd3693661b75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0mvgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_tf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m208\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;31m#==============================================================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sik4hi/tensorflow-vgg-master/Pretraining/vgg16_seed.pyc\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, rgb, classes, train_mode)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu7\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc8\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fc8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m#self.prob = tf.nn.softmax(self.fc8, name=\"prob\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sik4hi/tensorflow-vgg-master/Pretraining/vgg16_seed.pyc\u001b[0m in \u001b[0;36mfc_layer\u001b[0;34m(self, bottom, in_size, out_size, name)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfc_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbiases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_fc_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbottom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sik4hi/tensorflow-vgg-master/Pretraining/vgg16_seed.pyc\u001b[0m in \u001b[0;36mget_fc_var\u001b[0;34m(self, in_size, out_size, name)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# initial_value = tf.truncated_normal([in_size, out_size], 0.0, 0.001)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mvar_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0min_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_weights_W\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         weight_decay = tf.mul(tf.nn.l2_loss(weights), self.wd,\n\u001b[1;32m    137\u001b[0m                                       name='weight_loss')\n",
      "\u001b[0;32m/home/sik4hi/tensorflow-vgg-master/Pretraining/vgg16_seed.pyc\u001b[0m in \u001b[0;36mget_var\u001b[0;34m(self, var_shape, name, idx, var_name)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0mvar_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mvar_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Simple tester for the vgg19_trainable\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import vgg16_seed as vgg16\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "PRETRAINED_MODEL_PATH= None #\"/mnt/data3/related_dataset/pretrained/ckpt_dir\"\n",
    "WEIGHT_PATH = \"/home/sik4hi/tensorflow-vgg-master/Pretraining/vgg-epoch-78.npy\"\n",
    "N_EPOCHS = 300\n",
    "INIT_LEARNING_RATE = 0.01\n",
    "WEIGHT_DECAY_RATE = 0.0005\n",
    "MOMENTUM = 0.9\n",
    "IMAGE_HEIGHT  = 224    #960\n",
    "IMAGE_WIDTH   = 224    #720\n",
    "NUM_CHANNELS  = 3\n",
    "BATCH_SIZE = 90\n",
    "N_CLASSES = 1000\n",
    "DROPOUT = 0.50\n",
    "ckpt_dir = \"/mnt/data3/related_dataset/pretrained/ckpt_dir\"\n",
    "#LOGS_PATH = '/home/sik4hi/tensorflow_logs'\n",
    "WEIGHT_PATH = '.npy'\n",
    "TRAINSET_PATH = '/mnt/data1/Related_Dataset/Related_csv/related_image_fine_lables.csv'\n",
    "VALSET_PATH ='/mnt/data1/Related_Dataset/Related_csv/val_related_image_fine_lables.csv'\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "#=======================================================================================================\n",
    "# Reading Training data from CSV FILE\n",
    "#=======================================================================================================\n",
    "train_csv_path=open(TRAINSET_PATH,\"r\")\n",
    "train_filepaths=[]\n",
    "train_labels=[]\n",
    "for line in train_csv_path:\n",
    "    filepath, label= line.split(\",\")\n",
    "    label= int(label)\n",
    "    train_filepaths.append(filepath)\n",
    "    train_labels.append(label)\n",
    "    \n",
    "val_csv_file=open(VALSET_PATH,\"r\")\n",
    "val_filepaths=[]\n",
    "val_labels=[]\n",
    "for line in val_csv_file:\n",
    "    filepath, label= line.split(\",\")\n",
    "    label= int(label)\n",
    "    val_filepaths.append(filepath)\n",
    "    val_labels.append(label)\n",
    "    \n",
    "with tf.device('/cpu:0'):\n",
    "    def _compute_longer_edge(height, width, new_shorter_edge):\n",
    "        return tf.cast(width*new_shorter_edge/height, tf.int32)\n",
    "\n",
    "    \n",
    "    train_image_path , train_label = tf.train.slice_input_producer([train_filepaths,train_labels]\n",
    "                                           ,capacity = 100000, shuffle=True)\n",
    "    \n",
    "    \n",
    "    train_image_content = tf.read_file(train_image_path)\n",
    "    train_image = tf.image.decode_jpeg(train_image_content, channels=3)\n",
    "    \n",
    "    shape = tf.shape(train_image)\n",
    "    height = shape[0]\n",
    "    width = shape[1]\n",
    "    new_shorter_edge = tf.constant(256, dtype=tf.int32)\n",
    "\n",
    "    height_smaller_than_width = tf.less_equal(height, width)\n",
    "    new_height_and_width = tf.cond(\n",
    "        height_smaller_than_width,\n",
    "        lambda: (new_shorter_edge, _compute_longer_edge(height, width, new_shorter_edge)),\n",
    "        lambda: (_compute_longer_edge(width, height, new_shorter_edge), new_shorter_edge)\n",
    "    )\n",
    "    size = tf.cast([new_height_and_width[0], new_height_and_width[1]], tf.int32)\n",
    "    train_image = tf.image.resize_images(train_image, size)\n",
    "    size = tf.cast([IMAGE_HEIGHT, IMAGE_WIDTH, 3], tf.int32)\n",
    "    train_image = tf.random_crop(train_image, size)\n",
    "    train_image = tf.image.random_flip_left_right(train_image)\n",
    "    train_image = tf.cast(train_image, tf.float32)/255. # necessary for mapping rgb channels from 0-255 to 0-1 float.\n",
    "    train_label = tf.cast(train_label, tf.int64) # unnecessary\n",
    "    train_image_batch, train_label_batch = tf.train.batch([train_image, train_label], batch_size=BATCH_SIZE,\n",
    "                                                                  capacity = 1000 + 3*BATCH_SIZE, \n",
    "                                                                  num_threads=7)\n",
    "    \n",
    "    \n",
    "    val_image_path , val_label = tf.train.slice_input_producer([val_filepaths,val_labels]\n",
    "                                           ,capacity = 20000)\n",
    "    \n",
    "    \n",
    "    val_image_content = tf.read_file(val_image_path)\n",
    "    val_image = tf.image.decode_jpeg(val_image_content, channels=3)\n",
    "    \n",
    "    shape = tf.shape(val_image)\n",
    "    height = shape[0]\n",
    "    width = shape[1]\n",
    "    new_shorter_edge = tf.constant(256, dtype=tf.int32)\n",
    "\n",
    "    height_smaller_than_width = tf.less_equal(height, width)\n",
    "    new_height_and_width = tf.cond(\n",
    "        height_smaller_than_width,\n",
    "        lambda: (new_shorter_edge, _compute_longer_edge(height, width, new_shorter_edge)),\n",
    "        lambda: (_compute_longer_edge(width, height, new_shorter_edge), new_shorter_edge)\n",
    "    )\n",
    "    size = tf.cast([new_height_and_width[0], new_height_and_width[1]], tf.int32)\n",
    "    val_image = tf.image.resize_images(val_image, size)\n",
    "    \n",
    "    size = tf.cast([IMAGE_HEIGHT, IMAGE_WIDTH, 3], tf.int32)\n",
    "    val_image = tf.random_crop(val_image, size)\n",
    "    \n",
    "    #val_image = tf.image.random_flip_left_right(val_image)\n",
    "    val_image = tf.cast(val_image, tf.float32)/255. # necessary for mapping rgb channels from 0-255 to 0-1 float.\n",
    "    val_label = tf.cast(val_label, tf.int64) # unnecessary\n",
    "    val_image_batch, val_label_batch = tf.train.batch([val_image, val_label], batch_size=BATCH_SIZE,\n",
    "                                                                  capacity = 1000 + 3*BATCH_SIZE, \n",
    "                                                                  num_threads=7)\n",
    "    \n",
    "with tf.device('/gpu:0'):\n",
    "   \n",
    "    \n",
    "    \n",
    "    #images_tf = tf.placeholder(tf.float32, [None, 224, 224, 3])\n",
    "    #labels_tf = tf.placeholder(tf.int64)\n",
    "    train_mode = tf.placeholder(tf.bool)\n",
    "\n",
    "    vgg = vgg16.Vgg16(\"./vgg-epoch-78.npy\")\n",
    "    \n",
    "    if train_mode is not None:\n",
    "        images_tf=tf.cond(train_mode, lambda:train_image_batch, lambda:val_image_batch)\n",
    "    if train_mode is not None:\n",
    "        labels_tf=tf.cond(train_mode, lambda:train_label_batch, lambda:val_label_batch)\n",
    "                          \n",
    "    \n",
    "    vgg.build(images_tf,classes=208, train_mode=train_mode)\n",
    "\n",
    "    #==============================================================================================================\n",
    "    # Defining Loss, could be changed from cross entropy depending on needs. The current configuration works well on\n",
    "    # multiclass (not hot-encoded vectors) prediction like ImageNET.\n",
    "    #==============================================================================================================\n",
    "    with tf.name_scope('Loss'):\n",
    "        loss_tf = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(vgg.fc8, labels_tf), name='loss_tf')\n",
    "        l2_loss=tf.reduce_sum(tf.get_collection(\"losses\"))\n",
    "        \n",
    "        loss_tf2 =loss_tf + l2_loss\n",
    "\n",
    "    # ==============================================================================================================\n",
    "    # Optimizer, again it can be changed to any function provided by Tensorflow. You can simply use commented out line\n",
    "    # instead of explicitly computing gradients, if you are not interested in creating summaries of gradients.\n",
    "    # ==============================================================================================================\n",
    "    #train_op = tf.train.MomentumOptimizer(learning_rate, MOMENTUM).minimize(loss_tf2)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate=0.0001,epsilon=0.1).minimize(loss_tf2)\n",
    "    #optimizer = tf.train.MomentumOptimizer(learning_rate, MOMENTUM)\n",
    "    #grads_and_vars = optimizer.compute_gradients(loss_tf)\n",
    "    #grads_and_vars = map(\n",
    "     #   lambda gv: (gv[0], gv[1]) if ('conv6' in gv[1].name or 'GAP' in gv[1].name) else (gv[0] * 0.1, gv[1]),\n",
    "      #  grads_and_vars)\n",
    "    #grads_and_vars = [(tf.clip_by_value(gv[0], -5., 5.), gv[1]) for gv in grads_and_vars]\n",
    "    #train_op = optimizer.apply_gradients(grads_and_vars)\n",
    "\n",
    "\n",
    "    # ===================================================================================================================\n",
    "    # Accuracy for the current batch\n",
    "    # ===================================================================================================================\n",
    "    correct_pred = tf.equal(tf.argmax(vgg.fc8, 1), labels_tf)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "with tf.device('/cpu:0'):\n",
    "    accuracy_top5= tf.reduce_mean(tf.cast(tf.nn.in_top_k(vgg.fc8,labels_tf,5), tf.float32))\n",
    "\n",
    "with tf.device('/cpu:0'):    \n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "    saver = tf.train.Saver(max_to_keep=150)\n",
    "    \n",
    "with tf.device('/gpu:0'):\n",
    "    sess = tf.Session()\n",
    "    init_op = tf.group(tf.initialize_all_variables(),\n",
    "                       tf.initialize_local_variables())\n",
    "    sess.run(init_op)\n",
    "    if PRETRAINED_MODEL_PATH:\n",
    "        print \"using Pretrained model\"\n",
    "        ckpt = tf.train.get_checkpoint_state(PRETRAINED_MODEL_PATH)\n",
    "        print(ckpt)\n",
    "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
    "        \n",
    "    coord=tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch=52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_loss_list, train_accuracy_list, plot_train_loss, plot_train_accuracy,l2_loss_list, plot_l2_loss =  [], [], [], [], [], []\n",
    "train_top5_list, plot_train_top5, val_top5_list, plot_val_top5 = [], [], [], []\n",
    "val_loss_list , val_accuracy_list ,plot_val_loss, plot_val_accuracy = [], [], [], []\n",
    "\n",
    "try:   \n",
    "    while not coord.should_stop() and epoch< N_EPOCHS:\n",
    "        epoch+=1\n",
    "        epoch_start_time = time.time()\n",
    "        print((186531 / BATCH_SIZE))\n",
    "        for i in xrange((186531/ BATCH_SIZE)):\n",
    "            _, train_loss,l2_train_loss, train_accuracy ,train_top5= sess.run(\n",
    "               [train_op, loss_tf, l2_loss, accuracy, accuracy_top5],feed_dict={train_mode: True})\n",
    "\n",
    "            train_loss_list.append(train_loss)\n",
    "            train_accuracy_list.append(train_accuracy)\n",
    "            l2_loss_list.append(l2_train_loss)\n",
    "            train_top5_list.append(train_top5)\n",
    "            sys.stdout.write('\\r\\r' + \"Iteration:\" + str(i)+ \"  Loss: \"+ str(train_loss)+ \" L2 Loss: \"+ str(l2_train_loss))\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        \n",
    "        train_loss_mean = np.mean(train_loss_list)\n",
    "        train_accuracy_mean = np.mean(train_accuracy_list)\n",
    "        train_top5_mean = np.mean(train_top5_list)\n",
    "        l2_loss_mean = np.mean(l2_loss_list)\n",
    "        \n",
    "        plot_train_loss.append(train_loss_mean)\n",
    "        plot_train_accuracy.append(train_accuracy_mean)\n",
    "        plot_train_top5.append(train_top5_mean)\n",
    "        plot_l2_loss.append(l2_loss_mean)\n",
    "      \n",
    "        train_loss_list = []\n",
    "        train_accuracy_list = []\n",
    "        train_top5_list = []\n",
    "        l2_loss_list=[]\n",
    "        \n",
    "        print((19201 / BATCH_SIZE))\n",
    "        for i in xrange((19201/ BATCH_SIZE)):\n",
    "            val_loss, val_accuracy, val_top5 = sess.run(\n",
    "               [loss_tf, accuracy, accuracy_top5],feed_dict={train_mode: False})\n",
    "\n",
    "            val_loss_list.append(val_loss)\n",
    "            val_accuracy_list.append(val_accuracy)\n",
    "            val_top5_list.append(val_top5)\n",
    "            sys.stdout.write('\\r\\r' + \"Iteration:\" + str(i)+ \"  Loss: \"+ str(val_loss))\n",
    "            sys.stdout.flush()\n",
    "        \n",
    "        \n",
    "        val_loss_mean = np.mean(val_loss_list)\n",
    "        val_accuracy_mean = np.mean(val_accuracy_list)\n",
    "        val_top5_mean = np.mean(val_top5_list)\n",
    "        \n",
    "        plot_val_loss.append(val_loss_mean)\n",
    "        plot_val_accuracy.append(val_accuracy_mean)\n",
    "        plot_val_top5.append(val_top5_mean)\n",
    "      \n",
    "        val_loss_list = []\n",
    "        val_accuracy_list = []\n",
    "        val_top5_list = []        \n",
    "            \n",
    "\n",
    "        clear_output()\n",
    "        print \"===========**Training ACCURACY**================\"\n",
    "        print \"Epoch:\", epoch\n",
    "        print 'Training Top5 : ', train_top5_mean \n",
    "        print 'Training Accuracy: ', train_accuracy_mean       \n",
    "        print \"Training Loss:\", train_loss_mean \n",
    "        print \"L2 Loss:\", l2_loss_mean\n",
    "        \n",
    "        print \"===========**VALIDATION ACCURACY**================\"\n",
    "        print 'Epoch:', epoch\n",
    "        print 'Validation Top5: ', val_top5_mean\n",
    "        print 'Validation Accuracy: ', val_accuracy_mean\n",
    "        print \"Validation Loss:\", val_loss_mean\n",
    "        \n",
    "        print 'Time Elapsed for Epoch:' + str(epoch) + ' is ' + str(\n",
    "            (time.time() - epoch_start_time) / 60.) + ' minutes'\n",
    "\n",
    "        plt.figure(1) \n",
    "        aa = plt.plot(plot_l2_loss,'r')\n",
    "        plt.title(\"L2 LOSS\")\n",
    "        plt.figure(2) \n",
    "        aa = plt.plot(plot_train_loss,'r',label=\"Training\")\n",
    "        bb = plt.plot(plot_val_loss,'g',label=\"Validation\")\n",
    "        plt.title(\"Cross Entropy Loss\")\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        plt.figure(3)\n",
    "        cc = plt.plot(plot_train_accuracy,'r',label=\"Training\")\n",
    "        dd = plt.plot(plot_val_accuracy,'g',label=\"Validation\")\n",
    "        plt.title(\"Top 1 Accuracy\")\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        plt.figure(4)\n",
    "        cc = plt.plot(plot_train_top5,'r',label=\"Training\")\n",
    "        dd = plt.plot(plot_val_top5,'g',label=\"Validation\")\n",
    "        plt.title(\"Top 5 Accuracy\")\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        saver.save(sess, ckpt_dir + \"/model-rel.ckpt\", global_step=epoch)\n",
    "        #vgg.save_npy(sess, '/mnt/data3/related_dataset/weights/vgg-rel-epoch-' + str(epoch) + '.npy')\n",
    "        ofile  = open('relatedwval.csv', \"a\")\n",
    "        writer = csv.writer(ofile)\n",
    "        timep=((time.time() - epoch_start_time) / 60.)\n",
    "        writer.writerow([train_loss_mean,train_accuracy_mean,train_top5_mean,val_loss_mean,val_accuracy_mean,val_top5_mean,l2_loss_mean,timep,epoch])\n",
    "        ofile.close()\n",
    "except tf.errors.OutOfRangeError:\n",
    "    print (\"out of range\")\n",
    "finally:\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    print(\"requesting stop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg.save_npy(sess, '/mnt/data3/related_dataset/npy/fine/vgg-rel-epoch-' + str(epoch) + '.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
