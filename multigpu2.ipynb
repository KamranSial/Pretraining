{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1_1/conv1_1_filters_W:0\n",
      "conv1_2/conv1_2_filters_W:0\n",
      "conv2_1/conv2_1_filters_W:0\n",
      "conv2_2/conv2_2_filters_W:0\n",
      "conv3_1/conv3_1_filters_W:0\n",
      "conv3_2/conv3_2_filters_W:0\n",
      "conv3_3/conv3_3_filters_W:0\n",
      "conv4_1/conv4_1_filters_W:0\n",
      "conv4_2/conv4_2_filters_W:0\n",
      "conv4_3/conv4_3_filters_W:0\n",
      "conv5_1/conv5_1_filters_W:0\n",
      "conv5_2/conv5_2_filters_W:0\n",
      "conv5_3/conv5_3_filters_W:0\n",
      "fc6/fc6_weights_W:0\n",
      "fc7/fc7_weights_W:0\n",
      "fc8/fc8_weights_W:0\n",
      "0\n",
      "conv1_1/conv1_1_filters_W:0\n",
      "conv1_2/conv1_2_filters_W:0\n",
      "conv2_1/conv2_1_filters_W:0\n",
      "conv2_2/conv2_2_filters_W:0\n",
      "conv3_1/conv3_1_filters_W:0\n",
      "conv3_2/conv3_2_filters_W:0\n",
      "conv3_3/conv3_3_filters_W:0\n",
      "conv4_1/conv4_1_filters_W:0\n",
      "conv4_2/conv4_2_filters_W:0\n",
      "conv4_3/conv4_3_filters_W:0\n",
      "conv5_1/conv5_1_filters_W:0\n",
      "conv5_2/conv5_2_filters_W:0\n",
      "conv5_3/conv5_3_filters_W:0\n",
      "fc6/fc6_weights_W:0\n",
      "fc7/fc7_weights_W:0\n",
      "fc8/fc8_weights_W:0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import vgg16_modified as vgg16\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import sys\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "PRETRAINED_MODEL_PATH= \"/home/sik4hi/ckpt_dir\"\n",
    "N_EPOCHS = 300\n",
    "INIT_LEARNING_RATE = 0.01\n",
    "WEIGHT_DECAY_RATE = 0.0005\n",
    "MOMENTUM = 0.9\n",
    "IMAGE_HEIGHT  = 224    #960\n",
    "IMAGE_WIDTH   = 224    #720\n",
    "NUM_CHANNELS  = 3\n",
    "BATCH_SIZE = 180\n",
    "N_CLASSES = 1000\n",
    "DROPOUT = 0.50\n",
    "NUM_GPUS=2\n",
    "ckpt_dir = \"/home/sik4hi/ckpt_dir\"\n",
    "LOGS_PATH = '/home/sik4hi/tensorflow_logs'\n",
    "WEIGHT_PATH = '.npy'\n",
    "TRAINSET_PATH0 = '/mnt/data1/imagenet-data/csv-files/train/imagenetdata0.csv'\n",
    "TRAINSET_PATH1 = '/mnt/data1/imagenet-data/csv-files/train/imagenetdata1.csv'\n",
    "TRAINSET_PATH2 = '/mnt/data1/imagenet-data/csv-files/train/imagenetdata2.csv'\n",
    "TRAINSET_PATH3 = '/mnt/data1/imagenet-data/csv-files/train/imagenetdata3.csv'\n",
    "TRAINSET_PATH4 = '/mnt/data1/imagenet-data/csv-files/train/imagenetdata4.csv'\n",
    "TRAINSET_PATH5 = '/mnt/data1/imagenet-data/csv-files/train/imagenetdata5.csv'\n",
    "TRAINSET_PATH6 = '/mnt/data1/imagenet-data/csv-files/train/imagenetdata6.csv'\n",
    "TRAINSET_PATH7 = '/mnt/data1/imagenet-data/csv-files/train/imagenetdata7.csv'\n",
    "TRAINSET_PATH8 = '/mnt/data1/imagenet-data/csv-files/train/imagenetdata8.csv'\n",
    "TRAINSET_PATH9 = '/mnt/data1/imagenet-data/csv-files/train/imagenetdata9.csv'\n",
    "\n",
    "VALSET_PATH0 ='/mnt/data1/imagenet-data/csv-files/val/imagenetdata0.csv'\n",
    "VALSET_PATH1 ='/mnt/data1/imagenet-data/csv-files/val/imagenetdata1.csv'\n",
    "VALSET_PATH2 ='/mnt/data1/imagenet-data/csv-files/val/imagenetdata2.csv'\n",
    "VALSET_PATH3 ='/mnt/data1/imagenet-data/csv-files/val/imagenetdata3.csv'\n",
    "VALSET_PATH4 ='/mnt/data1/imagenet-data/csv-files/val/imagenetdata4.csv'\n",
    "\n",
    "\n",
    "def _tower_loss(images, labels,train_mode, scope):\n",
    "    # Build inference Graph.\n",
    "    \n",
    "    vgg = vgg16.Vgg16()\n",
    "    vgg.build(images, train_mode)\n",
    "    weights_only = filter(lambda x: x.name.endswith('W:0'), tf.trainable_variables())\n",
    "    for x in xrange(len(weights_only)):\n",
    "        print (weights_only[x].name)\n",
    "    # print number of variables used: 143667240 variables, i.e. ideal size = 548MB\n",
    "    print vgg.get_var_count()\n",
    "    \n",
    "    # Build the portion of the Graph calculating the losses. Note that we will\n",
    "    # assemble the total_loss using a custom function below.\n",
    "    loss_tf = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(vgg.prob, labels), name='loss_tf')\n",
    "    #loss_summary = tf.summary.scalar(\"loss\", loss_tf)\n",
    "    weights_only = filter( lambda x: x.name.endswith('W:0'), tf.trainable_variables())\n",
    "    weight_decay = tf.reduce_mean(tf.add_n([tf.nn.l2_loss(x) for x in weights_only])) * WEIGHT_DECAY_RATE\n",
    "    total_loss = loss_tf + weight_decay\n",
    "    \n",
    "    #correct_pred = tf.equal(tf.argmax(vgg.prob, 1), labels)\n",
    "    #accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "    \n",
    "    return total_loss,loss_tf#, accuracy\n",
    "\n",
    "\n",
    "def average_gradients(tower_grads):\n",
    "    average_grads = []\n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "    # Note that each grad_and_vars looks like the following:\n",
    "    #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n",
    "        grads = []\n",
    "        for g, _ in grad_and_vars:\n",
    "        # Add 0 dimension to the gradients to represent the tower.\n",
    "            expanded_g = tf.expand_dims(g, 0)\n",
    "\n",
    "            # Append on a 'tower' dimension which we will average over below.\n",
    "            grads.append(expanded_g)\n",
    "\n",
    "        # Average over the 'tower' dimension.\n",
    "        grad = tf.concat(0,grads)\n",
    "        grad = tf.reduce_mean(grad, 0)\n",
    "\n",
    "        # Keep in mind that the Variables are redundant because they are shared\n",
    "        # across towers. So .. we will just return the first tower's pointer to\n",
    "        # the Variable.\n",
    "        v = grad_and_vars[0][1]\n",
    "        grad_and_var = (grad, v)\n",
    "        average_grads.append(grad_and_var)\n",
    "    return average_grads\n",
    "\n",
    "def _compute_longer_edge(height, width, new_shorter_edge):\n",
    "    return tf.cast(width*new_shorter_edge/height, tf.int32)\n",
    "    \n",
    "\n",
    "    \"\"\"Train CIFAR-10 for a number of steps.\"\"\"\n",
    "with tf.Graph().as_default(), tf.device('/gpu:0'):\n",
    "    #learning_rate = tf.placeholder(tf.float32, [])\n",
    "    images_tf = tf.placeholder(tf.float32, [BATCH_SIZE, 224, 224, 3])\n",
    "    labels_tf = tf.placeholder(tf.int64,[BATCH_SIZE])\n",
    "    train_mode = tf.placeholder(tf.bool)\n",
    "        \n",
    "    opt = tf.train.AdamOptimizer(0.01,epsilon=0.1)\n",
    "    csv_path = tf.train.string_input_producer([TRAINSET_PATH0, TRAINSET_PATH1\n",
    "                                              , TRAINSET_PATH2, TRAINSET_PATH3,\n",
    "                                               TRAINSET_PATH4, TRAINSET_PATH5\n",
    "                                              , TRAINSET_PATH6, TRAINSET_PATH7, \n",
    "                                               TRAINSET_PATH8, TRAINSET_PATH9\n",
    "                                              ], shuffle=True)\n",
    "    textReader = tf.TextLineReader()\n",
    "    _, csv_content = textReader.read(csv_path)\n",
    "    im_name, im_label = tf.decode_csv(csv_content, record_defaults=[[\"\"], [1]])\n",
    "\n",
    "    im_content = tf.read_file(im_name)\n",
    "    train_image = tf.image.decode_jpeg(im_content, channels=3)\n",
    "    \n",
    "    # train_image = augment(train_image)\n",
    "    #size = tf.cast([IMAGE_HEIGHT, IMAGE_WIDTH], tf.int32)\n",
    "    #train_image = tf.image.resize_images(train_image, size)\n",
    "    train_label = tf.cast(im_label, tf.int64) # unnecessary\n",
    "    \n",
    "    shape = tf.shape(train_image)\n",
    "    height = shape[0]\n",
    "    width = shape[1]\n",
    "    new_shorter_edge = tf.constant(256, dtype=tf.int32)\n",
    "\n",
    "    height_smaller_than_width = tf.less_equal(height, width)\n",
    "    new_height_and_width = tf.cond(\n",
    "        height_smaller_than_width,\n",
    "        lambda: (new_shorter_edge, _compute_longer_edge(height, width, new_shorter_edge)),\n",
    "        lambda: (_compute_longer_edge(width, height, new_shorter_edge), new_shorter_edge)\n",
    "    )\n",
    "    size = tf.cast([new_height_and_width[0], new_height_and_width[1]], tf.int32)\n",
    "    train_image = tf.image.resize_images(train_image, size)\n",
    "    size = tf.cast([IMAGE_HEIGHT, IMAGE_WIDTH, 3], tf.int32)\n",
    "    train_image = tf.random_crop(train_image, size)\n",
    "    train_image = tf.image.random_flip_left_right(train_image)\n",
    "    train_image = tf.cast(train_image, tf.float32)/255. # necessary for mapping rgb channels from 0-255 to 0-1 float.\n",
    "    #train_label_batch = tf.one_hot(train_label_batch, 1000)\n",
    "    train_image_batch, train_label_batch = tf.train.shuffle_batch([train_image, train_label], batch_size=BATCH_SIZE,\n",
    "                                                                  capacity = 1000 + 3*BATCH_SIZE, min_after_dequeue = 1000)\n",
    "   \n",
    "\n",
    "    images_splits = tf.split(0, NUM_GPUS, images_tf)\n",
    "    labels_splits = tf.split(0, NUM_GPUS, labels_tf)\n",
    "        \n",
    "        # Calculate the gradients for each model tower.\n",
    "    tower_grads = []\n",
    "    #tower_accuracy = []\n",
    "    for i in xrange(NUM_GPUS):\n",
    "        with tf.device('/gpu:%d' % i):\n",
    "            with tf.name_scope('%s_%d' % ('tower', i)) as scope:\n",
    "                # Calculate the loss for one tower of the CIFAR model. This function\n",
    "                # constructs the entire CIFAR model but shares the variables across\n",
    "                # all towers.\n",
    "                    \n",
    "                loss_tf2, loss_tf = _tower_loss(images_splits[i], labels_splits[i],train_mode, scope)\n",
    "                # Reuse variables for the next tower.\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "                # Retain the summaries from the final tower.\n",
    "                # summaries = tf.get_collection(tf.GraphKeys.SUMMARIES, scope)\n",
    "\n",
    "                # Calculate the gradients for the batch of data on this CIFAR tower.\n",
    "                grads = opt.compute_gradients(loss_tf2)\n",
    "                    \n",
    "                # Keep track of the gradients across all towers.\n",
    "                tower_grads.append(grads)\n",
    "                #tower_accuracy.append(accuracy)\n",
    "    # We must calculate the mean of each gradient. Note that this is the\n",
    "    # synchronization point across all towers.\n",
    "    grads = average_gradients(tower_grads)\n",
    "    #total_accuracy=tf.reduce_mean(tower_accuracy)\n",
    "    # Add a summary to track the learning rate.\n",
    "    # summaries.append(tf.contrib.deprecated.scalar_summary('learning_rate', lr))\n",
    "\n",
    "    # Add histograms for gradients.\n",
    "    #for grad, var in grads:\n",
    "    #      if grad is not None:\n",
    "    #            summaries.append(\n",
    "    #            tf.contrib.deprecated.histogram_summary(var.op.name + '/gradients',\n",
    "    #                                            grad))\n",
    "\n",
    "    # Apply the gradients to adjust the shared variables.\n",
    "    apply_gradient_op = opt.apply_gradients(grads)\n",
    "\n",
    "    # Add histograms for trainable variables.\n",
    "    #for var in tf.trainable_variables():\n",
    "    #      summaries.append(tf.contrib.deprecated.histogram_summary(var.op.name, var))\n",
    "\n",
    "    # Track the moving averages of all trainable variables.\n",
    "    #variable_averages = tf.train.ExponentialMovingAverage(cifar10.MOVING_AVERAGE_DECAY, global_step)\n",
    "    #variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "\n",
    "    # Group all updates to into a single train op.\n",
    "    #train_op = tf.group(apply_gradient_op, variables_averages_op)\n",
    "    train_op = apply_gradient_op\n",
    "                            \n",
    "    # Create a saver.\n",
    "    if not os.path.exists(ckpt_dir):\n",
    "        os.makedirs(ckpt_dir)\n",
    "    saver = tf.train.Saver(max_to_keep=5)\n",
    "    # Build the summary operation from the last tower summaries.\n",
    "    #summary_op = tf.contrib.deprecated.merge_summary(summaries)\n",
    "\n",
    "    # Build an initialization operation to run below.\n",
    "    init= tf.group(tf.initialize_all_variables(),\n",
    "                    tf.initialize_local_variables())\n",
    "\n",
    "    # Start running operations on the Graph. allow_soft_placement must be set to\n",
    "    # True to build towers on GPU, as some of the ops do not have GPU\n",
    "    # implementations.\n",
    "    \n",
    "    \n",
    "    config=tf.ConfigProto(\n",
    "            allow_soft_placement=True,\n",
    "            log_device_placement=False)\n",
    "    #config.gpu_options.allow_growth=True\n",
    "    #config=tf.GPUOptions(allow_growth=True)\n",
    "    #config += tf.GPUOptions(allow_growth=True) \n",
    "    sess = tf.Session(config=config)\n",
    "    sess.run(init)\n",
    "    # Start the queue runners.\n",
    "    tf.train.start_queue_runners(sess=sess)\n",
    "\n",
    "    #summary_writer = tf.summary.FileWriter(FLAGS.train_dir, sess.graph)\n",
    "\n",
    "        \n",
    "    loss_list, train_list, plot_loss, plot_acc , loss_list2 , val_list ,plot_loss2, plot_acc2, total_loss_list1, total_loss_list2, plot_ttloss, plot_tvloss  = [], [], [], [], [], [], [], [], [], [], [], []\n",
    "    #summary_writer = tf.summary.FileWriter(LOGS_PATH, graph=tf.get_default_graph())\n",
    "    steps = 1\n",
    "    count = 1\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7117\n",
      "iteration:0 Time Elapsed for 10 Iterations:0 is 27.038244009 Seconds\n",
      "iteration:10 Time Elapsed for 10 Iterations:10 is 52.8240458965 Seconds\n",
      "iteration:20 Time Elapsed for 10 Iterations:20 is 49.4625160694 Seconds\n",
      "iteration:30 Time Elapsed for 10 Iterations:30 is 51.1385438442 Seconds\n",
      "iteration:40 Time Elapsed for 10 Iterations:40 is 49.0846631527 Seconds\n",
      "iteration:50 Time Elapsed for 10 Iterations:50 is 47.1501510143 Seconds\n",
      "iteration:60 Time Elapsed for 10 Iterations:60 is 46.5889210701 Seconds\n",
      "iteration:70 Time Elapsed for 10 Iterations:70 is 43.87220788 Seconds\n",
      "iteration:80 Time Elapsed for 10 Iterations:80 is 44.5144331455 Seconds\n",
      "iteration:90 Time Elapsed for 10 Iterations:90 is 43.0252549648 Seconds\n",
      "iteration:100 Time Elapsed for 10 Iterations:100 is 42.9697568417 Seconds\n",
      "iteration:110 Time Elapsed for 10 Iterations:110 is 43.027998209 Seconds\n",
      "iteration:120 Time Elapsed for 10 Iterations:120 is 44.3915710449 Seconds\n",
      "iteration:130 Time Elapsed for 10 Iterations:130 is 46.9864411354 Seconds\n",
      "iteration:140 Time Elapsed for 10 Iterations:140 is 43.7809090614 Seconds\n",
      "iteration:150 Time Elapsed for 10 Iterations:150 is 44.8874959946 Seconds\n",
      "iteration:160 Time Elapsed for 10 Iterations:160 is 45.1910970211 Seconds\n",
      "iteration:170 Time Elapsed for 10 Iterations:170 is 42.5411930084 Seconds\n",
      "iteration:180 Time Elapsed for 10 Iterations:180 is 43.3809409142 Seconds\n",
      "iteration:190 Time Elapsed for 10 Iterations:190 is 45.5428898335 Seconds\n",
      "iteration:200 Time Elapsed for 10 Iterations:200 is 48.2807161808 Seconds\n",
      "iteration:210 Time Elapsed for 10 Iterations:210 is 43.8400218487 Seconds\n",
      "iteration:219"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ac03a94fb41e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1281144\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1281144\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mtrain_imbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_image_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         _, train_loss = sess.run(\n\u001b[1;32m     10\u001b[0m                     \u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_tf\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 717\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    718\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 915\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    916\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m--> 965\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 972\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    973\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m    952\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m    953\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in xrange(N_EPOCHS):\n",
    "    train_correct = 0\n",
    "    train_data = 0\n",
    "    epoch_start_time = time.time()\n",
    "    iteration_start_time = time.time()\n",
    "    print((1281144/ BATCH_SIZE))\n",
    "    for i in xrange((1281144/ BATCH_SIZE)):\n",
    "        train_imbatch, train_labatch = sess.run([train_image_batch, train_label_batch])\n",
    "        _, train_loss = sess.run(\n",
    "                    [train_op, loss_tf],\n",
    "                    feed_dict={images_tf: train_imbatch, labels_tf:\n",
    "               train_labatch, train_mode: True})\n",
    "\n",
    "        loss_list.append(train_loss)\n",
    "        #train_list.append(train_accuracy)\n",
    "        #total_loss_list1.append(total_loss)\n",
    "        sys.stdout.write('\\r' + 'iteration:' + str(i))\n",
    "        sys.stdout.flush() \n",
    "        if (i) % 10 == 0:\n",
    "            print ' Time Elapsed for 10 Iterations:' + str(i) + ' is ' + str(\n",
    "                (time.time() - iteration_start_time)) + ' Seconds' \n",
    "            iteration_start_time = time.time()\n",
    "          \n",
    "\n",
    "    clear_output()\n",
    "    #t = np.mean(train_list)\n",
    "    l = np.mean(loss_list)\n",
    "    #ttl = np.mean(total_loss_list1)\n",
    "    print \"===========**Training ACCURACY**================\"\n",
    "    print \"Epoch\", epoch + 1#, \"Iteration\", steps\n",
    "    #print 'Training Accuracy: ', t\n",
    "    print \"Training Loss:\", l \n",
    "    #print \"Total Training Loss:\", ttl\n",
    "                \n",
    "    plot_loss.append(l)\n",
    "    #plot_acc.append(t)\n",
    "    #plot_ttloss.append(ttl)\n",
    "      \n",
    "      \n",
    "    loss_list = []\n",
    "    #train_list = []\n",
    "    #total_loss_list1=[]\n",
    "                \n",
    "            \n",
    "            #INIT_LEARNING_RATE *= 0.99\n",
    "    \n",
    "    print 'Time Elapsed for Epoch:' + str(epoch + 1) + ' is ' + str(\n",
    "            (time.time() - epoch_start_time) / 60.) + ' minutes'\n",
    "    plt.figure(1) \n",
    "    aa = plt.plot(plot_loss,'r',label=\"Training\")\n",
    "    plt.title(\"LOSS\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.show()\n",
    "    loss_list2 = []\n",
    "    val_list = []\n",
    "    total_loss_list2=[]\n",
    "    \n",
    "    #if (epoch % 1 == 0):            \n",
    "    #    saver.save(sess, ckpt_dir + \"/model.ckpt\", global_step=epoch)\n",
    "    # test savel\n",
    "    #vgg.save_npy(sess, './test-save'+str(epoch)+'.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
